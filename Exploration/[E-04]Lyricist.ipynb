{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuck-genre",
   "metadata": {},
   "source": [
    "## Project - 가사 한 줄 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "molecular-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/exploration-4-writer/data': File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p ~/aiffel/exploration-4-writer/models\n",
    "# !ln -s ~/data/* ~/aiffel/exploration-4-writer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "planned-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 29 11:05:20 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           Off  | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   57C    P0    61W / 149W |   2356MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-surname",
   "metadata": {},
   "source": [
    "### 모듈 임포트, 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "behind-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기:  187088\n",
      "Examples:\n",
      " [\"You won't regret it baby, and you surely won't forget it baby\", \"It's unbelieveable how your body's calling for me\", \"I can just hear it callin' callin' for me My body's callin' for you\", \"My body's callin' for you\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "txt_file_path = os.getenv('HOME') + '/aiffel/exploration-4-writer/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw) ## extend(iterable): 리스트를 풀어서 넣어준다.\n",
    "\n",
    "print(\"데이터 크기: \", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[5:9])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-nebraska",
   "metadata": {},
   "source": [
    "### 데이터 전처리 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "sensitive-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-paris",
   "metadata": {},
   "source": [
    "`'<start> ' + sentence + ' <end>'`를 했을 때 빈 sentence의 경우 길이가 14인 문장이 됩니다. 따라서 길이가 14를 넘고(초과), 단어로 나눠봤을 때 15개 이하인 문장들만 사용하도록 하겠습니다. 지나치게 긴 문장의 경우 padding 값이 커져 문제가 생길 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "oriented-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "        \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    split_preprocessed_sentence = preprocessed_sentence.split()\n",
    "    if len(preprocessed_sentence) > 14 and len(split_preprocessed_sentence)<=15:\n",
    "        corpus.append(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "velvet-cruise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156174"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "indonesian-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyric_tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,\n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',\n",
    "                                                           maxlen=15)\n",
    "    \n",
    "    print(tensor, tokenizer)\n",
    "    \n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "documentary-content",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   4 186 ...   0   0   0]\n",
      " [  2  10 588 ...   0   0   0]\n",
      " [  2  52  41 ...   0   0   0]\n",
      " ...\n",
      " [  2   4  92 ...   0   0   0]\n",
      " [  2   9 156 ...   0   0   0]\n",
      " [  2 178  16 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f68e945a590>\n"
     ]
    }
   ],
   "source": [
    "tensor, tokenizer = lyric_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fabulous-supplier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    4  186    7  824    5   90    4   68   52    3    0    0    0\n",
      "     0]\n",
      " [   2   10  588    7    5   47   47    3    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2   52   41   98 6829    3    0    0    0    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "crazy-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "russian-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156174, 15)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "continuous-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   4 186   7 824   5  90   4  68  52   3   0   0   0]\n",
      "[  4 186   7 824   5  90   4  68  52   3   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]\n",
    "tgt_input = tensor[:, 1:]\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "competitive-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156174\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(src_input))\n",
    "print(tokenizer.num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-child",
   "metadata": {},
   "source": [
    "### 모델구성, 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "monetary-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "infrared-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124939, 14)\n",
      "Target Train: (124939, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape) ## X_train\n",
    "print(\"Target Train:\", dec_train.shape) ## y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "previous-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source label: (31235, 14)\n",
      "Target label: (31235, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source label:\", enc_val.shape) ## X_test\n",
    "print(\"Target label:\", dec_val.shape) ## y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-block",
   "metadata": {},
   "source": [
    "__FURTHER TODO__\n",
    "\n",
    "- [ ] Difference between `tf.data.Dataset` and `(x_train, y_train)` with `.fit(batch_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "reverse-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 128\n",
    "# steps_per_epoch = len(enc_train) // BATCH_SIZE \n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_t = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "# dataset_t = dataset_t.shuffle(BUFFER_SIZE)\n",
    "# dataset_t = dataset_t.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "editorial-fashion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((128, 14), (128, 14)), types: (tf.int32, tf.int32)>\n",
      "<TensorSliceDataset shapes: ((14,), (14,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-stock",
   "metadata": {},
   "source": [
    "모델을 Subclass 형태로 만들어줬습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "endless-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "empirical-scientist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12001\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.num_words+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "municipal-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "hidden_size = 128\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "verbal-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [-1.95629200e-05,  7.33937632e-05,  1.73669134e-04, ...,\n",
       "          2.43371731e-04, -1.48584048e-04,  1.18084659e-04],\n",
       "        [-4.49699073e-05,  2.23724783e-05,  2.02248630e-04, ...,\n",
       "          2.59413762e-04, -2.05968434e-04,  1.48178122e-04],\n",
       "        ...,\n",
       "        [ 1.15513605e-04, -8.91171294e-06,  4.84945602e-04, ...,\n",
       "          2.74290534e-04, -3.30548995e-04,  4.87204670e-04],\n",
       "        [ 1.02441598e-04, -6.20158171e-05,  4.24062222e-04, ...,\n",
       "          2.15534179e-04, -3.53535521e-04,  4.83087439e-04],\n",
       "        [ 6.17828555e-05, -1.24747690e-04,  3.25003668e-04, ...,\n",
       "          1.38312578e-04, -3.97020922e-04,  4.77695867e-04]],\n",
       "\n",
       "       [[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [-5.00525966e-05,  6.54206451e-06,  1.46118036e-04, ...,\n",
       "          1.85706071e-04, -1.20977267e-04,  9.93929425e-05],\n",
       "        [-5.41529189e-05,  1.28921019e-05,  1.05283325e-04, ...,\n",
       "          2.38185094e-04, -2.00110284e-04,  1.70949032e-04],\n",
       "        ...,\n",
       "        [-6.65119223e-05, -1.40212185e-04,  2.45129660e-04, ...,\n",
       "          2.02153751e-04, -2.68935866e-04, -1.38222720e-04],\n",
       "        [-1.02443213e-04, -2.05714387e-04,  1.37860930e-04, ...,\n",
       "          1.08944660e-04, -3.63386935e-04, -6.98821241e-05],\n",
       "        [-1.46816397e-04, -2.85265414e-04,  3.62519786e-05, ...,\n",
       "          2.60830548e-05, -4.60340001e-04, -8.47919728e-06]],\n",
       "\n",
       "       [[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [-4.85744567e-06, -2.05570741e-05,  5.99562445e-05, ...,\n",
       "          1.26684856e-04, -9.26378561e-05,  7.98972760e-05],\n",
       "        [-4.00399549e-05, -1.50869846e-06,  3.03688212e-05, ...,\n",
       "          1.64071636e-04, -1.11248082e-04,  1.19450960e-04],\n",
       "        ...,\n",
       "        [ 9.56038130e-05, -4.00279299e-04, -1.18545489e-04, ...,\n",
       "         -2.19958587e-04, -7.31784618e-04,  7.11709508e-05],\n",
       "        [ 3.69203372e-05, -4.81779804e-04, -2.15083448e-04, ...,\n",
       "         -2.51171528e-04, -7.85451382e-04,  1.12223264e-04],\n",
       "        [-2.58864548e-05, -5.64506103e-04, -2.95082922e-04, ...,\n",
       "         -2.78462598e-04, -8.47448478e-04,  1.43244630e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [ 8.73257231e-05, -1.82860222e-05,  2.45326137e-05, ...,\n",
       "          1.50292588e-04, -1.00379630e-05,  8.25324023e-05],\n",
       "        [ 1.56364535e-04, -2.74916092e-05,  1.79836316e-05, ...,\n",
       "          1.84446078e-04,  8.99736260e-05,  8.39420609e-05],\n",
       "        ...,\n",
       "        [-2.20507776e-04, -5.52818005e-04, -2.36631124e-04, ...,\n",
       "         -2.89299234e-04, -6.48777117e-04,  3.61334212e-04],\n",
       "        [-2.77741463e-04, -6.38559344e-04, -2.69869546e-04, ...,\n",
       "         -3.14443663e-04, -7.68138911e-04,  3.41911742e-04],\n",
       "        [-3.28971510e-04, -7.17793999e-04, -2.97862891e-04, ...,\n",
       "         -3.40015627e-04, -8.86081485e-04,  3.11603973e-04]],\n",
       "\n",
       "       [[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [ 1.05867024e-04, -1.19351535e-05,  7.96882741e-05, ...,\n",
       "          1.47047060e-04, -1.32315196e-04,  7.42759075e-05],\n",
       "        [ 2.15837776e-04, -3.87474465e-05,  1.40193833e-05, ...,\n",
       "          2.37098109e-04, -1.46196646e-04,  1.62755212e-04],\n",
       "        ...,\n",
       "        [-3.27072594e-05, -8.94158366e-05, -2.44478579e-04, ...,\n",
       "          1.03176360e-04, -1.35614639e-04,  4.27355320e-04],\n",
       "        [-8.94282275e-05, -1.71469568e-04, -2.76859471e-04, ...,\n",
       "          2.97020015e-05, -2.66127987e-04,  4.25777020e-04],\n",
       "        [-1.45502330e-04, -2.63085210e-04, -3.01649387e-04, ...,\n",
       "         -3.80702149e-05, -4.03885759e-04,  4.13730275e-04]],\n",
       "\n",
       "       [[ 8.65616767e-06,  1.70873900e-05,  8.85860354e-05, ...,\n",
       "          9.16310528e-05, -6.93949769e-05,  4.62196222e-05],\n",
       "        [ 4.05277206e-05,  2.93826247e-06,  7.76470406e-05, ...,\n",
       "          1.05854670e-04, -1.38679636e-04,  4.63948272e-05],\n",
       "        [ 7.04495615e-05,  2.61650330e-05,  1.00219884e-04, ...,\n",
       "          3.55618104e-05, -2.39790650e-04,  2.00122977e-05],\n",
       "        ...,\n",
       "        [-1.80620540e-04, -4.28442465e-04, -2.03256204e-04, ...,\n",
       "         -2.66017276e-04, -5.99371269e-04,  3.55894997e-04],\n",
       "        [-2.31808910e-04, -5.14651765e-04, -2.34443331e-04, ...,\n",
       "         -2.86445080e-04, -6.94900576e-04,  3.44173663e-04],\n",
       "        [-2.79884291e-04, -5.97897917e-04, -2.61250825e-04, ...,\n",
       "         -3.08789982e-04, -7.96784356e-04,  3.21010157e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): \n",
    "    #print(type(src_sample))\n",
    "    #print(src_sample.shape)\n",
    "    break\n",
    "    \n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "independent-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     multiple                  384032    \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               multiple                  82432     \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               multiple                  131584    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  1548129   \n",
      "=================================================================\n",
      "Total params: 2,146,177\n",
      "Trainable params: 2,146,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "built-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.getenv('HOME') + '/aiffel/exploration-4-writer/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "referenced-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emb-32-hid-200-epoch:03-val_loss:2.75-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:03-val_loss:2.89-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:01-val_loss:2.85-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:01-val_loss:3.10-LSTM.hdf5',\n",
       " 'emb-32-hid-200-epoch:01-val_loss:2.90-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:01-val_loss:2.92-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:03-val_loss:2.93-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:04-val_loss:2.77-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:05-val_loss:2.79-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:02-val_loss:2.81-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:05-val_loss:2.87-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:01-val_loss:3.07-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:03-val_loss:2.78-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:03-val_loss:5.19-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:04-val_loss:2.88-LSTM.hdf5',\n",
       " 'emb-32-hid-1024-epoch:01-val_loss:4.06-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:05-val_loss:2.90-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:01-val_loss:5.83-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:05-val_loss:2.77-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:02-val_loss:2.98-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:02-val_loss:2.94-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:03-val_loss:2.81-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:02-val_loss:5.38-LSTM.hdf5',\n",
       " '.ipynb_checkpoints',\n",
       " 'emb-32-hid-200-epoch:04-val_loss:2.74-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:02-val_loss:2.74-LSTM.hdf5',\n",
       " 'emb-32-hid-200-epoch:02-val_loss:2.79-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:01-val_loss:2.94-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:02-val_loss:2.84-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:04-val_loss:2.80-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:04-val_loss:2.91-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:03-val_loss:2.69-LSTM.hdf5']"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "critical-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath=os.path.join(checkpoint_filepath, \"best_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "prescribed-stuff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3905/3905 [==============================] - 65s 16ms/step - loss: 3.0536 - val_loss: 3.0013\n",
      "Epoch 2/10\n",
      "3905/3905 [==============================] - 62s 16ms/step - loss: 2.8990 - val_loss: 2.9201\n",
      "Epoch 3/10\n",
      "3905/3905 [==============================] - 62s 16ms/step - loss: 2.7861 - val_loss: 2.8741\n",
      "Epoch 4/10\n",
      "3905/3905 [==============================] - 62s 16ms/step - loss: 2.6990 - val_loss: 2.8511\n",
      "Epoch 5/10\n",
      "3905/3905 [==============================] - 62s 16ms/step - loss: 2.6374 - val_loss: 2.8350\n",
      "Epoch 6/10\n",
      "3905/3905 [==============================] - 62s 16ms/step - loss: 2.5866 - val_loss: 2.8258\n",
      "Epoch 7/10\n",
      " 100/3905 [..............................] - ETA: 55s - loss: 2.5078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-465-830e59399003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m lyricist.fit(enc_train, dec_train, epochs=EPOCH, validation_data=(enc_val, dec_val),\n\u001b[0;32m---> 22\u001b[0;31m           callbacks=[model_checkpoint_callback, early_stopping]) \n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=4e-3)\n",
    "\n",
    "EPOCH = 10\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none')\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "file_name = f\"emb-{embedding_size}-hid-{hidden_size}-\" + \"epoch:{epoch:02d}-val_loss:{val_loss:.2f}-LSTM.hdf5\" \n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_filepath, file_name),\n",
    "    save_weights_only=True, \n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.03, patience=3)\n",
    "\n",
    "lyricist.fit(enc_train, dec_train, epochs=EPOCH, validation_data=(enc_val, dec_val),\n",
    "          callbacks=[model_checkpoint_callback, early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "applicable-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.getenv('HOME') + '/aiffel/exploration-4-writer/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "agreed-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emb-32-hid-128-epoch:06-val_loss:2.83-LSTM.hdf5',\n",
       " 'emb-32-hid-200-epoch:03-val_loss:2.75-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:03-val_loss:2.89-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:01-val_loss:2.85-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:05-val_loss:2.83-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:03-val_loss:2.87-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:01-val_loss:3.10-LSTM.hdf5',\n",
       " 'emb-32-hid-200-epoch:01-val_loss:2.90-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:01-val_loss:2.92-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:03-val_loss:2.93-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:04-val_loss:2.77-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:05-val_loss:2.79-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:02-val_loss:2.81-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:05-val_loss:2.87-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:01-val_loss:3.07-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:03-val_loss:2.78-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:03-val_loss:5.19-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:04-val_loss:2.88-LSTM.hdf5',\n",
       " 'emb-32-hid-1024-epoch:01-val_loss:4.06-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:05-val_loss:2.90-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:02-val_loss:2.92-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:01-val_loss:5.83-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:05-val_loss:2.77-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:01-val_loss:3.00-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:02-val_loss:3.14-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:02-val_loss:2.98-LSTM.hdf5',\n",
       " 'emb-32-hid-32-epoch:02-val_loss:2.94-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:03-val_loss:2.81-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:01-val_loss:3.18-LSTM.hdf5',\n",
       " 'emb-32-hid-128-epoch:04-val_loss:2.85-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:02-val_loss:5.38-LSTM.hdf5',\n",
       " '.ipynb_checkpoints',\n",
       " 'emb-32-hid-200-epoch:04-val_loss:2.74-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:02-val_loss:2.74-LSTM.hdf5',\n",
       " 'emb-32-hid-200-epoch:02-val_loss:2.79-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:01-val_loss:2.94-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:02-val_loss:2.84-LSTM.hdf5',\n",
       " 'emb-32-hid-150-epoch:04-val_loss:2.80-LSTM.hdf5',\n",
       " 'emb-32-hid-64-epoch:04-val_loss:2.91-LSTM.hdf5',\n",
       " 'emb-32-hid-350-epoch:03-val_loss:2.69-LSTM.hdf5']"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "premium-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath=os.path.join(checkpoint_filepath, 'emb-size:16-hidden-size:100-LSTM.hdf5')\n",
    "#print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "hairy-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "unauthorized-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyricist.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "rational-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        predict=model(test_tensor)\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "    \n",
    "    generated = \"\"\n",
    "    \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "surface-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i always never be with you <end> '"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> I always \", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-beast",
   "metadata": {},
   "source": [
    "### FURTHER TODO\n",
    "- [ ] Difference between `tf.data.Dataset` and `(x_train, y_train)` with `.fit(batch_size)`\n",
    "- [ ] Why `save_weights_only=False` does not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-garlic",
   "metadata": {},
   "source": [
    "### 소감\n",
    "\n",
    "무엇보다 `val_loss`가 적어진다고 자연어처리에서는 만능이 아니란 걸 깨달았습니다. 처음엔 Bidirectional 모델을 사용해봤는데, 헷갈리면 `<end>`를 붙이자 식으로 학습을 쉽게 해버리는 것 같아서 함정카드에 걸렸었습니다.\n",
    "\n",
    "여러번 실험을 해보면서 오히려 `val_loss`가 높아도 그럴듯한 문장을 생성하기도 하는 걸 보니 자연어처리가 쉽지 않다는 걸 다시 한번 깨달았습니다.\n",
    "\n",
    "또한 당연할 수도 있지만 `embedding_size`가 크다고 장땡이 아닌 것도 알았습니다. 정확히 word embedding이 어떻게 되는 지 특히 keras에서는 어떻게 진행하는 지 꼭 알아야봐야겠습니다.\n",
    "\n",
    "아지트에서 본 이창호 퍼실님의 댓글에서 퍼온 말로 이번 노드를 마무리 하겠습니다.\n",
    "\n",
    "_\"NLP에서 개인적으로 제가 매력을 느낀 부분은 모델의 정량적인 metric이 인간의 정성적인 evaluation과 항상 정비례하지 않는다는 점이었습니다.\"_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
